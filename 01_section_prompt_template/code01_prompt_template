from dotenv import load_dotenv

from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.schema.output_parser import StrOutputParser

# Load environment variables from a .env file
load_dotenv()

# Initialize the language model
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

# Create a chat prompt template
prompt = ChatPromptTemplate.from_messages([
    ("system", "Você é um assistente sucinto."),
    ("user", "{pergunta}")
])

# Create a chain that combines the prompt, LLM, and output parser
chain = prompt | llm | StrOutputParser()
print(chain.invoke({"pergunta": "Explique RAG em 2 frases."}))